{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclassMissing</th>\n",
       "      <th>workclassFederal-gov</th>\n",
       "      <th>workclassLocal-gov</th>\n",
       "      <th>workclassNever-worked</th>\n",
       "      <th>workclassPrivate</th>\n",
       "      <th>workclassSelf-emp-inc</th>\n",
       "      <th>workclassSelf-emp-not-inc</th>\n",
       "      <th>workclassState-gov</th>\n",
       "      <th>workclassWithout-pay</th>\n",
       "      <th>...</th>\n",
       "      <th>native-countryPortugal</th>\n",
       "      <th>native-countryPuerto-Rico</th>\n",
       "      <th>native-countryScotland</th>\n",
       "      <th>native-countrySouth</th>\n",
       "      <th>native-countryTaiwan</th>\n",
       "      <th>native-countryThailand</th>\n",
       "      <th>native-countryTrinadad-Tobago</th>\n",
       "      <th>native-countryUnited-States</th>\n",
       "      <th>native-countryVietnam</th>\n",
       "      <th>native-countryYugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.286609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.286609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.833773</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclassMissing  workclassFederal-gov  workclassLocal-gov  \\\n",
       "0 -1.286609                 0                     0                   0   \n",
       "1  0.395073                 0                     0                   0   \n",
       "2  0.029490                 0                     0                   1   \n",
       "3 -1.286609                 0                     0                   0   \n",
       "4  0.833773                 0                     0                   0   \n",
       "\n",
       "   workclassNever-worked  workclassPrivate  workclassSelf-emp-inc  \\\n",
       "0                      0                 1                      0   \n",
       "1                      0                 0                      1   \n",
       "2                      0                 0                      0   \n",
       "3                      0                 1                      0   \n",
       "4                      0                 0                      0   \n",
       "\n",
       "   workclassSelf-emp-not-inc  workclassState-gov  workclassWithout-pay  \\\n",
       "0                          0                   0                     0   \n",
       "1                          0                   0                     0   \n",
       "2                          0                   0                     0   \n",
       "3                          0                   0                     0   \n",
       "4                          0                   1                     0   \n",
       "\n",
       "             ...             native-countryPortugal  \\\n",
       "0            ...                                  0   \n",
       "1            ...                                  0   \n",
       "2            ...                                  0   \n",
       "3            ...                                  0   \n",
       "4            ...                                  0   \n",
       "\n",
       "   native-countryPuerto-Rico  native-countryScotland  native-countrySouth  \\\n",
       "0                          0                       0                    0   \n",
       "1                          0                       0                    0   \n",
       "2                          0                       0                    0   \n",
       "3                          0                       0                    0   \n",
       "4                          0                       0                    0   \n",
       "\n",
       "   native-countryTaiwan  native-countryThailand  \\\n",
       "0                     0                       0   \n",
       "1                     0                       0   \n",
       "2                     0                       0   \n",
       "3                     0                       0   \n",
       "4                     0                       0   \n",
       "\n",
       "   native-countryTrinadad-Tobago  native-countryUnited-States  \\\n",
       "0                              0                            1   \n",
       "1                              0                            1   \n",
       "2                              0                            1   \n",
       "3                              0                            1   \n",
       "4                              0                            1   \n",
       "\n",
       "   native-countryVietnam  native-countryYugoslavia  \n",
       "0                      0                         0  \n",
       "1                      0                         0  \n",
       "2                      0                         0  \n",
       "3                      0                         0  \n",
       "4                      0                         0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: outcome>50K, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data for training, validation and testing\n",
    "TRAIN_FILE = 'D:\\Study\\Ostfold\\MachineLearning\\git\\data\\ohenc_data_colNames.train';\n",
    "VAL_FILE = 'D:\\Study\\Ostfold\\MachineLearning\\git\\data\\ohenc_data_colNames.val';\n",
    "TEST_FILE = 'D:\\Study\\Ostfold\\MachineLearning\\git\\data\\ohenc_data_colNames.test';\n",
    "\n",
    "# use one of 2 labels\n",
    "redundant_label = 'outcome<50K'\n",
    "label_name = 'outcome>50K'\n",
    "\n",
    "# training data\n",
    "train = pd.read_table(TRAIN_FILE, sep=' ')\n",
    "train.pop(redundant_label)\n",
    "train_x, train_y = train, train.pop(label_name)\n",
    "\n",
    "# validation data\n",
    "val = pd.read_table(VAL_FILE, sep=' ')\n",
    "val.pop(redundant_label)\n",
    "val_x, val_y = val, val.pop(label_name)\n",
    "\n",
    "# testing data\n",
    "test = pd.read_table(TEST_FILE, sep=' ')\n",
    "test.pop(redundant_label)\n",
    "test_x, test_y = test, test.pop(label_name)\n",
    "\n",
    "display(train_x.head())\n",
    "display(train_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare loaders\n",
    "train = torch.utils.data.TensorDataset(torch.from_numpy(train_x.values).type(torch.FloatTensor), torch.from_numpy(train_y.values))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
    "train_loader_val = torch.utils.data.DataLoader(train, batch_size=10000, shuffle=True)\n",
    "\n",
    "val = torch.utils.data.TensorDataset(torch.from_numpy(val_x.values).type(torch.FloatTensor), torch.from_numpy(val_y.values))\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=10000, shuffle=True)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(torch.from_numpy(test_x.values).type(torch.FloatTensor), torch.from_numpy(test_y.values))\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net4HiddenLayers(nn.Module):\n",
    "    def __init__(self, nodes1, nodes2, nodes4, dropout):\n",
    "        super(Net4HiddenLayers, self).__init__()\n",
    "        self.fc1 = nn.Linear(108, nodes1)\n",
    "        self.fc1_bn = nn.BatchNorm1d(nodes1)\n",
    "        self.fc2 = nn.Linear(nodes1, nodes2)\n",
    "        self.fc2_bn = nn.BatchNorm1d(nodes2)\n",
    "        self.fc3 = nn.Linear(nodes2, nodes3)\n",
    "        self.fc3_bn = nn.BatchNorm1d(nodes3)\n",
    "        self.fc4 = nn.Linear(nodes3, nodes4)\n",
    "        self.fc4_bn = nn.BatchNorm1d(nodes4)\n",
    "        self.fc5 = nn.Linear(nodes4, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = F.relu(self.fc3_bn(self.fc3(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = F.relu(self.fc4_bn(self.fc4(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class Net3HiddenLayers(nn.Module):\n",
    "    def __init__(self, nodes1, nodes2, nodes3, dropout):\n",
    "        super(Net3HiddenLayers, self).__init__()\n",
    "        self.fc1 = nn.Linear(108, nodes1)\n",
    "        self.fc1_bn = nn.BatchNorm1d(nodes1)\n",
    "        self.fc2 = nn.Linear(nodes1, nodes2)\n",
    "        self.fc2_bn = nn.BatchNorm1d(nodes2)\n",
    "        self.fc3 = nn.Linear(nodes2, nodes3)\n",
    "        self.fc3_bn = nn.BatchNorm1d(nodes3)\n",
    "        self.fc4 = nn.Linear(nodes3, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = F.relu(self.fc3_bn(self.fc3(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class Net2HiddenLayers(nn.Module):\n",
    "    def __init__(self, nodes1, nodes2, dropout):\n",
    "        super(Net2HiddenLayers, self).__init__()\n",
    "        self.fc1 = nn.Linear(108, nodes1)\n",
    "        self.fc1_bn = nn.BatchNorm1d(nodes1)\n",
    "        self.fc2 = nn.Linear(nodes1, nodes2)\n",
    "        self.fc2_bn = nn.BatchNorm1d(nodes2)\n",
    "        self.fc3 = nn.Linear(nodes2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class Net1HiddenLayer(nn.Module):\n",
    "    def __init__(self, nodes, dropout):\n",
    "        super(Net1HiddenLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(108, nodes)\n",
    "        self.fc1_bn = nn.BatchNorm1d(nodes)\n",
    "        self.fc2 = nn.Linear(nodes, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train(epoch, optimizer, model, log_enable = False):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         if args.cuda:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if log_enable and (batch_idx % log_interval == 0):\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def evaluate(data_loader, data_set=\"validation\"):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in data_loader:\n",
    "#         if args.cuda:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    print('{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        data_set, test_loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n",
    "\n",
    "def train_and_eval(optimizer, model, epochs, log_enable=False):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(epoch, optimizer, model, log_enable)\n",
    "        if (log_enable):\n",
    "            evaluate(train_loader_val, \"training\")\n",
    "            evaluate(val_loader)\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    evaluate(train_loader_val, \"training\")\n",
    "    evaluate(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Adam optimizer\n",
      "0, hidden units[512, 128, 16], lr 0.008817740148838987, dropout 0.19292064211820775, l2_reg 0.06526312845736566\n",
      "training set: Average loss: 0.3870, Accuracy: 21584/26048 (82.86%)\n",
      "validation set: Average loss: 0.3935, Accuracy: 5348/6513 (82.11%)\n",
      "1, hidden units[512, 32], lr 0.0002197650292535493, dropout 0.12708883969802606, l2_reg 0.00019603703649661065\n",
      "training set: Average loss: 0.1949, Accuracy: 23778/26048 (91.29%)\n",
      "validation set: Average loss: 0.3864, Accuracy: 5465/6513 (83.91%)\n",
      "2, hidden units[512, 512], lr 0.0009722409087384057, dropout 0.6595924273002486, l2_reg 0.00018757377382423246\n",
      "training set: Average loss: 0.2443, Accuracy: 23106/26048 (88.71%)\n",
      "validation set: Average loss: 0.3414, Accuracy: 5529/6513 (84.89%)\n",
      "3, hidden units[512, 256, 128], lr 0.0003445814894676429, dropout 0.6628926041214146, l2_reg 0.00039927980952424554\n",
      "training set: Average loss: 0.2374, Accuracy: 23268/26048 (89.33%)\n",
      "validation set: Average loss: 0.3435, Accuracy: 5506/6513 (84.54%)\n",
      "4, hidden units[64], lr 0.00028947974285248535, dropout 0.28877378419424676, l2_reg 0.00025987618454731165\n",
      "training set: Average loss: 0.2829, Accuracy: 22681/26048 (87.07%)\n",
      "validation set: Average loss: 0.3228, Accuracy: 5538/6513 (85.03%)\n",
      "5, hidden units[1024, 512, 256], lr 0.0003397021969828694, dropout 0.5343030503529761, l2_reg 0.5396519082465817\n",
      "training set: Average loss: 0.5931, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.5947, Accuracy: 4928/6513 (75.66%)\n",
      "6, hidden units[32], lr 0.008200857463070962, dropout 0.319641020369604, l2_reg 0.05213295692896354\n",
      "training set: Average loss: 0.3539, Accuracy: 21923/26048 (84.16%)\n",
      "validation set: Average loss: 0.3655, Accuracy: 5413/6513 (83.11%)\n",
      "7, hidden units[1024, 64], lr 0.00024870809349494984, dropout 0.25930876644652545, l2_reg 0.000888946978065614\n",
      "training set: Average loss: 0.2353, Accuracy: 23353/26048 (89.65%)\n",
      "validation set: Average loss: 0.3355, Accuracy: 5512/6513 (84.63%)\n",
      "8, hidden units[512], lr 0.0017066349482145141, dropout 0.4841389216885861, l2_reg 0.004911740723651014\n",
      "training set: Average loss: 0.3117, Accuracy: 22279/26048 (85.53%)\n",
      "validation set: Average loss: 0.3313, Accuracy: 5457/6513 (83.79%)\n",
      "9, hidden units[1024, 512, 16], lr 0.0017484796530502363, dropout 0.2101854519468064, l2_reg 0.00012031756191844071\n",
      "training set: Average loss: 0.1795, Accuracy: 23879/26048 (91.67%)\n",
      "validation set: Average loss: 0.4841, Accuracy: 5481/6513 (84.15%)\n",
      "10, hidden units[256], lr 0.00023708632813271527, dropout 0.2557561280262316, l2_reg 0.03172058788870181\n",
      "training set: Average loss: 0.3350, Accuracy: 22113/26048 (84.89%)\n",
      "validation set: Average loss: 0.3483, Accuracy: 5441/6513 (83.54%)\n",
      "11, hidden units[512, 64, 32], lr 0.0020150741488961354, dropout 0.3292535314311945, l2_reg 0.036862963630654395\n",
      "training set: Average loss: 0.3514, Accuracy: 22070/26048 (84.73%)\n",
      "validation set: Average loss: 0.3613, Accuracy: 5447/6513 (83.63%)\n",
      "12, hidden units[128, 32], lr 0.005472661287177966, dropout 0.3286317921683938, l2_reg 0.19258534901638658\n",
      "training set: Average loss: 0.5625, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.5651, Accuracy: 4928/6513 (75.66%)\n",
      "13, hidden units[16], lr 0.002761393774986268, dropout 0.4664913379815119, l2_reg 0.0006355260097257456\n",
      "training set: Average loss: 0.3001, Accuracy: 22442/26048 (86.16%)\n",
      "validation set: Average loss: 0.3271, Accuracy: 5503/6513 (84.49%)\n",
      "14, hidden units[256], lr 0.001026814964706627, dropout 0.2374989147188579, l2_reg 0.00017644193531843555\n",
      "training set: Average loss: 0.2360, Accuracy: 23270/26048 (89.34%)\n",
      "validation set: Average loss: 0.3398, Accuracy: 5517/6513 (84.71%)\n",
      "15, hidden units[1024, 1024, 128], lr 0.0038724520964268203, dropout 0.14093899826785405, l2_reg 0.10606135572648695\n",
      "training set: Average loss: 0.4195, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.4260, Accuracy: 4928/6513 (75.66%)\n",
      "16, hidden units[128, 32], lr 0.0012335177716855266, dropout 0.15687126442364172, l2_reg 0.002848468834036609\n",
      "training set: Average loss: 0.2956, Accuracy: 22494/26048 (86.36%)\n",
      "validation set: Average loss: 0.3228, Accuracy: 5528/6513 (84.88%)\n",
      "17, hidden units[2048, 16], lr 0.005796083180479456, dropout 0.4252492403509315, l2_reg 0.027866623308903955\n",
      "training set: Average loss: 0.3440, Accuracy: 21996/26048 (84.44%)\n",
      "validation set: Average loss: 0.3568, Accuracy: 5438/6513 (83.49%)\n",
      "18, hidden units[2048, 512, 128], lr 0.0037615214034091298, dropout 0.21415421011010954, l2_reg 0.003846584314519104\n",
      "training set: Average loss: 0.3133, Accuracy: 22336/26048 (85.75%)\n",
      "validation set: Average loss: 0.3313, Accuracy: 5512/6513 (84.63%)\n",
      "19, hidden units[1024, 512, 32], lr 0.007888728595569786, dropout 0.46278391027024446, l2_reg 0.018991427686305084\n",
      "training set: Average loss: 0.3561, Accuracy: 21742/26048 (83.47%)\n",
      "validation set: Average loss: 0.3666, Accuracy: 5351/6513 (82.16%)\n",
      "20, hidden units[2048, 32, 16], lr 0.009549546419675165, dropout 0.3149058105123832, l2_reg 0.023314423143268235\n",
      "training set: Average loss: 0.3535, Accuracy: 21813/26048 (83.74%)\n",
      "validation set: Average loss: 0.3685, Accuracy: 5396/6513 (82.85%)\n",
      "21, hidden units[512], lr 0.0004285635016626703, dropout 0.35717927626869306, l2_reg 0.00022493337847767324\n",
      "training set: Average loss: 0.2479, Accuracy: 23100/26048 (88.68%)\n",
      "validation set: Average loss: 0.3341, Accuracy: 5506/6513 (84.54%)\n",
      "22, hidden units[16, 16], lr 0.00019006984887204743, dropout 0.39521262506830535, l2_reg 0.0033613310538593145\n",
      "training set: Average loss: 0.3022, Accuracy: 22452/26048 (86.19%)\n",
      "validation set: Average loss: 0.3261, Accuracy: 5509/6513 (84.58%)\n",
      "23, hidden units[128, 32, 16], lr 0.0002112450164715856, dropout 0.30796847777667846, l2_reg 0.2517630335096024\n",
      "training set: Average loss: 0.5704, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.5727, Accuracy: 4928/6513 (75.66%)\n",
      "24, hidden units[64], lr 0.0003202878454709068, dropout 0.31493314598010286, l2_reg 0.00043054761404702664\n",
      "training set: Average loss: 0.2847, Accuracy: 22658/26048 (86.99%)\n",
      "validation set: Average loss: 0.3225, Accuracy: 5543/6513 (85.11%)\n",
      "25, hidden units[1024], lr 0.0013662951891454662, dropout 0.5779006013958955, l2_reg 0.1585211864584887\n",
      "training set: Average loss: 0.4229, Accuracy: 20679/26048 (79.39%)\n",
      "validation set: Average loss: 0.4299, Accuracy: 5136/6513 (78.86%)\n",
      "26, hidden units[2048, 1024, 256], lr 0.0012432896299054714, dropout 0.26295344804661547, l2_reg 0.008864520869861392\n",
      "training set: Average loss: 0.3101, Accuracy: 22345/26048 (85.78%)\n",
      "validation set: Average loss: 0.3276, Accuracy: 5506/6513 (84.54%)\n",
      "27, hidden units[32], lr 0.0010043647069194984, dropout 0.4601700240845963, l2_reg 0.0008587542063566212\n",
      "training set: Average loss: 0.2952, Accuracy: 22511/26048 (86.42%)\n",
      "validation set: Average loss: 0.3239, Accuracy: 5516/6513 (84.69%)\n",
      "28, hidden units[16], lr 0.0021334720043965924, dropout 0.10722242191797451, l2_reg 0.15692589490540965\n",
      "training set: Average loss: 0.4241, Accuracy: 20772/26048 (79.75%)\n",
      "validation set: Average loss: 0.4313, Accuracy: 5147/6513 (79.03%)\n",
      "29, hidden units[2048, 256], lr 0.00870567957605268, dropout 0.49828844450295484, l2_reg 0.0006891452901930507\n",
      "training set: Average loss: 0.3102, Accuracy: 22281/26048 (85.54%)\n",
      "validation set: Average loss: 0.3312, Accuracy: 5491/6513 (84.31%)\n",
      "30, hidden units[64], lr 0.0005502030255325719, dropout 0.5252249101250089, l2_reg 0.010286190499214441\n",
      "training set: Average loss: 0.3125, Accuracy: 22302/26048 (85.62%)\n",
      "validation set: Average loss: 0.3298, Accuracy: 5499/6513 (84.43%)\n",
      "31, hidden units[1024], lr 0.0004988751903286512, dropout 0.5752493345349976, l2_reg 0.10563320746669654\n",
      "training set: Average loss: 0.3900, Accuracy: 21536/26048 (82.68%)\n",
      "validation set: Average loss: 0.3988, Accuracy: 5338/6513 (81.96%)\n",
      "32, hidden units[512, 256, 64], lr 0.0005304292077439, dropout 0.17891317809813595, l2_reg 0.0003556193970284548\n",
      "training set: Average loss: 0.1453, Accuracy: 24382/26048 (93.60%)\n",
      "validation set: Average loss: 0.4781, Accuracy: 5423/6513 (83.26%)\n",
      "33, hidden units[64], lr 0.0010373093386849034, dropout 0.19153718212309323, l2_reg 0.01158236419108721\n",
      "training set: Average loss: 0.3137, Accuracy: 22292/26048 (85.58%)\n",
      "validation set: Average loss: 0.3306, Accuracy: 5484/6513 (84.20%)\n",
      "34, hidden units[256, 128, 32], lr 0.0014112059854403597, dropout 0.6733210603032013, l2_reg 0.5061049037217967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: Average loss: 0.5916, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.5932, Accuracy: 4928/6513 (75.66%)\n",
      "35, hidden units[2048], lr 0.0003249533170129262, dropout 0.381941374409544, l2_reg 0.9372571544652458\n",
      "training set: Average loss: 0.6152, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.6164, Accuracy: 4928/6513 (75.66%)\n",
      "36, hidden units[256, 16], lr 0.0005717946142694649, dropout 0.46523891276893126, l2_reg 0.001821698869940675\n",
      "training set: Average loss: 0.2891, Accuracy: 22689/26048 (87.10%)\n",
      "validation set: Average loss: 0.3248, Accuracy: 5553/6513 (85.26%)\n",
      "37, hidden units[1024, 256], lr 0.00525813800072652, dropout 0.6744389032918569, l2_reg 0.7035084210643078\n",
      "training set: Average loss: 0.6037, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.6051, Accuracy: 4928/6513 (75.66%)\n",
      "38, hidden units[512, 128, 32], lr 0.006296566518349741, dropout 0.24877006707539231, l2_reg 0.1588067475169318\n",
      "training set: Average loss: 0.5603, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.5630, Accuracy: 4928/6513 (75.66%)\n",
      "39, hidden units[256, 128, 16], lr 0.001150345996113912, dropout 0.1900552072567258, l2_reg 0.19429293036935866\n",
      "training set: Average loss: 0.5657, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.5682, Accuracy: 4928/6513 (75.66%)\n",
      "40, hidden units[256], lr 0.00014300269973398127, dropout 0.1647338991254288, l2_reg 0.0007497416382297006\n",
      "training set: Average loss: 0.2824, Accuracy: 22700/26048 (87.15%)\n",
      "validation set: Average loss: 0.3209, Accuracy: 5541/6513 (85.08%)\n",
      "41, hidden units[256], lr 0.0005113631129865373, dropout 0.4361688938884052, l2_reg 0.2478871857931971\n",
      "training set: Average loss: 0.4784, Accuracy: 19792/26048 (75.98%)\n",
      "validation set: Average loss: 0.4832, Accuracy: 4928/6513 (75.66%)\n",
      "42, hidden units[1024, 512, 16], lr 0.0015425913067813426, dropout 0.3766395583511686, l2_reg 0.02175281537189535\n",
      "training set: Average loss: 0.3350, Accuracy: 22114/26048 (84.90%)\n",
      "validation set: Average loss: 0.3489, Accuracy: 5461/6513 (83.85%)\n",
      "43, hidden units[512], lr 0.0006392292664601745, dropout 0.2724240215374721, l2_reg 0.01088510950455673\n",
      "training set: Average loss: 0.3144, Accuracy: 22252/26048 (85.43%)\n",
      "validation set: Average loss: 0.3314, Accuracy: 5476/6513 (84.08%)\n",
      "44, hidden units[512], lr 0.0017729141198430532, dropout 0.5484457765143909, l2_reg 0.0014397937660411873\n",
      "training set: Average loss: 0.3016, Accuracy: 22395/26048 (85.98%)\n",
      "validation set: Average loss: 0.3292, Accuracy: 5493/6513 (84.34%)\n",
      "45, hidden units[256], lr 0.0005527286592215673, dropout 0.24475162048214233, l2_reg 0.000793674029199211\n",
      "training set: Average loss: 0.2783, Accuracy: 22740/26048 (87.30%)\n",
      "validation set: Average loss: 0.3235, Accuracy: 5532/6513 (84.94%)\n",
      "46, hidden units[128], lr 0.001092181945668056, dropout 0.48425097116398463, l2_reg 0.04097965671520527\n",
      "training set: Average loss: 0.3439, Accuracy: 21980/26048 (84.38%)\n",
      "validation set: Average loss: 0.3571, Accuracy: 5429/6513 (83.36%)\n",
      "47, hidden units[1024], lr 0.00017600968406596314, dropout 0.6531193819658481, l2_reg 0.00010303294485480662\n",
      "training set: Average loss: 0.2626, Accuracy: 22940/26048 (88.07%)\n",
      "validation set: Average loss: 0.3276, Accuracy: 5546/6513 (85.15%)\n",
      "48, hidden units[2048], lr 0.0007369942273470323, dropout 0.5556707525153407, l2_reg 0.0007556622548538433\n",
      "training set: Average loss: 0.2880, Accuracy: 22603/26048 (86.77%)\n",
      "validation set: Average loss: 0.3269, Accuracy: 5524/6513 (84.81%)\n",
      "49, hidden units[1024, 512, 512], lr 0.0006572089233938175, dropout 0.13416623153728982, l2_reg 0.000823319711827003\n",
      "training set: Average loss: 0.1870, Accuracy: 23803/26048 (91.38%)\n",
      "validation set: Average loss: 0.3942, Accuracy: 5486/6513 (84.23%)\n"
     ]
    }
   ],
   "source": [
    "log_interval = 1000\n",
    "epochs = 100\n",
    "max_count = 50\n",
    "print(\"Using Adam optimizer\") \n",
    "      \n",
    "hidden_set = [2048, 1024, 512, 256, 128, 64, 32, 16] \n",
    "for count in range(max_count):\n",
    "    lr = 10**random.uniform(-2, -4)\n",
    "    dropout = random.uniform(0.1,0.7)\n",
    "    layers = random.randint(1, 4)\n",
    "    hidden_units = random.randint(1, size=layers)\n",
    "    l2_reg = 10**random.uniform(-4,0)\n",
    "    for i in range(layers):\n",
    "        hidden_units[i] = hidden_set[random.randint(0,8)]\n",
    "        \n",
    "    hidden_units = sorted(hidden_units, reverse=True)\n",
    "    \n",
    "    torch.manual_seed(1234)\n",
    "    print(\"{}, hidden units{}, lr {}, dropout {}, l2_reg {}\".format(\n",
    "        count, hidden_units, lr, dropout, l2_reg))\n",
    "    \n",
    "    if layers == 1:\n",
    "        model = Net1HiddenLayer(hidden_units[0].item(), dropout)\n",
    "    elif layers == 2:\n",
    "        model = Net2HiddenLayers(hidden_units[0].item(), hidden_units[1].item(), \n",
    "                                 dropout)\n",
    "    elif layers == 3:\n",
    "        model = Net3HiddenLayers(hidden_units[0].item(), hidden_units[1].item(), \n",
    "                                 hidden_units[2].item(), dropout)\n",
    "    elif layers == 4:\n",
    "        model = Net4HiddenLayers(hidden_units[0].item(), hidden_units[1].item(), \n",
    "                                 hidden_units[2].item(), hidden_units[3].item(), \n",
    "                                 dropout)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg)\n",
    "    train_and_eval(optimizer, model, epochs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Adam optimizer Finer search\n",
      "0, hidden units[1024, 256], lr 0.001, dropout 0.5, l2_reg 0.001\n",
      "Train Epoch: 1 [0/26048 (0%)]\tLoss: 0.710675\n",
      "Train Epoch: 1 [12800/26048 (49%)]\tLoss: 0.324187\n",
      "Train Epoch: 1 [25600/26048 (98%)]\tLoss: 0.302295\n",
      "training set: Average loss: 0.3031, Accuracy: 22401/26048 (86.00%)\n",
      "validation set: Average loss: 0.3213, Accuracy: 5547/6513 (85.17%)\n",
      "\n",
      "\n",
      "Train Epoch: 2 [0/26048 (0%)]\tLoss: 0.369849\n",
      "Train Epoch: 2 [12800/26048 (49%)]\tLoss: 0.304860\n",
      "Train Epoch: 2 [25600/26048 (98%)]\tLoss: 0.303176\n",
      "training set: Average loss: 0.2976, Accuracy: 22434/26048 (86.13%)\n",
      "validation set: Average loss: 0.3231, Accuracy: 5527/6513 (84.86%)\n",
      "\n",
      "\n",
      "Train Epoch: 3 [0/26048 (0%)]\tLoss: 0.320941\n",
      "Train Epoch: 3 [12800/26048 (49%)]\tLoss: 0.341252\n",
      "Train Epoch: 3 [25600/26048 (98%)]\tLoss: 0.335361\n",
      "training set: Average loss: 0.2934, Accuracy: 22515/26048 (86.44%)\n",
      "validation set: Average loss: 0.3234, Accuracy: 5512/6513 (84.63%)\n",
      "\n",
      "\n",
      "Train Epoch: 4 [0/26048 (0%)]\tLoss: 0.307163\n",
      "Train Epoch: 4 [12800/26048 (49%)]\tLoss: 0.270758\n",
      "Train Epoch: 4 [25600/26048 (98%)]\tLoss: 0.294755\n",
      "training set: Average loss: 0.2905, Accuracy: 22544/26048 (86.55%)\n",
      "validation set: Average loss: 0.3203, Accuracy: 5541/6513 (85.08%)\n",
      "\n",
      "\n",
      "Train Epoch: 5 [0/26048 (0%)]\tLoss: 0.263507\n",
      "Train Epoch: 5 [12800/26048 (49%)]\tLoss: 0.253041\n",
      "Train Epoch: 5 [25600/26048 (98%)]\tLoss: 0.270853\n",
      "training set: Average loss: 0.2883, Accuracy: 22556/26048 (86.59%)\n",
      "validation set: Average loss: 0.3223, Accuracy: 5532/6513 (84.94%)\n",
      "\n",
      "\n",
      "Train Epoch: 6 [0/26048 (0%)]\tLoss: 0.333850\n",
      "Train Epoch: 6 [12800/26048 (49%)]\tLoss: 0.267293\n",
      "Train Epoch: 6 [25600/26048 (98%)]\tLoss: 0.297098\n",
      "training set: Average loss: 0.2846, Accuracy: 22625/26048 (86.86%)\n",
      "validation set: Average loss: 0.3197, Accuracy: 5542/6513 (85.09%)\n",
      "\n",
      "\n",
      "Train Epoch: 7 [0/26048 (0%)]\tLoss: 0.322459\n",
      "Train Epoch: 7 [12800/26048 (49%)]\tLoss: 0.357385\n",
      "Train Epoch: 7 [25600/26048 (98%)]\tLoss: 0.329966\n",
      "training set: Average loss: 0.2845, Accuracy: 22598/26048 (86.76%)\n",
      "validation set: Average loss: 0.3224, Accuracy: 5540/6513 (85.06%)\n",
      "\n",
      "\n",
      "Train Epoch: 8 [0/26048 (0%)]\tLoss: 0.310596\n",
      "Train Epoch: 8 [12800/26048 (49%)]\tLoss: 0.296976\n",
      "Train Epoch: 8 [25600/26048 (98%)]\tLoss: 0.312672\n",
      "training set: Average loss: 0.2815, Accuracy: 22662/26048 (87.00%)\n",
      "validation set: Average loss: 0.3199, Accuracy: 5545/6513 (85.14%)\n",
      "\n",
      "\n",
      "Train Epoch: 9 [0/26048 (0%)]\tLoss: 0.329971\n",
      "Train Epoch: 9 [12800/26048 (49%)]\tLoss: 0.308941\n",
      "Train Epoch: 9 [25600/26048 (98%)]\tLoss: 0.267000\n",
      "training set: Average loss: 0.2775, Accuracy: 22693/26048 (87.12%)\n",
      "validation set: Average loss: 0.3210, Accuracy: 5555/6513 (85.29%)\n",
      "\n",
      "\n",
      "Train Epoch: 10 [0/26048 (0%)]\tLoss: 0.244725\n",
      "Train Epoch: 10 [12800/26048 (49%)]\tLoss: 0.273516\n",
      "Train Epoch: 10 [25600/26048 (98%)]\tLoss: 0.271675\n",
      "training set: Average loss: 0.2759, Accuracy: 22707/26048 (87.17%)\n",
      "validation set: Average loss: 0.3206, Accuracy: 5545/6513 (85.14%)\n",
      "\n",
      "\n",
      "Train Epoch: 11 [0/26048 (0%)]\tLoss: 0.263777\n",
      "Train Epoch: 11 [12800/26048 (49%)]\tLoss: 0.370775\n",
      "Train Epoch: 11 [25600/26048 (98%)]\tLoss: 0.295269\n",
      "training set: Average loss: 0.2747, Accuracy: 22670/26048 (87.03%)\n",
      "validation set: Average loss: 0.3258, Accuracy: 5544/6513 (85.12%)\n",
      "\n",
      "\n",
      "Train Epoch: 12 [0/26048 (0%)]\tLoss: 0.259163\n",
      "Train Epoch: 12 [12800/26048 (49%)]\tLoss: 0.272610\n",
      "Train Epoch: 12 [25600/26048 (98%)]\tLoss: 0.302024\n",
      "training set: Average loss: 0.2731, Accuracy: 22706/26048 (87.17%)\n",
      "validation set: Average loss: 0.3210, Accuracy: 5560/6513 (85.37%)\n",
      "\n",
      "\n",
      "Train Epoch: 13 [0/26048 (0%)]\tLoss: 0.232566\n",
      "Train Epoch: 13 [12800/26048 (49%)]\tLoss: 0.232697\n",
      "Train Epoch: 13 [25600/26048 (98%)]\tLoss: 0.280876\n",
      "training set: Average loss: 0.2732, Accuracy: 22750/26048 (87.34%)\n",
      "validation set: Average loss: 0.3231, Accuracy: 5520/6513 (84.75%)\n",
      "\n",
      "\n",
      "Train Epoch: 14 [0/26048 (0%)]\tLoss: 0.404233\n",
      "Train Epoch: 14 [12800/26048 (49%)]\tLoss: 0.285041\n",
      "Train Epoch: 14 [25600/26048 (98%)]\tLoss: 0.289575\n",
      "training set: Average loss: 0.2695, Accuracy: 22809/26048 (87.57%)\n",
      "validation set: Average loss: 0.3235, Accuracy: 5529/6513 (84.89%)\n",
      "\n",
      "\n",
      "Train Epoch: 15 [0/26048 (0%)]\tLoss: 0.228911\n",
      "Train Epoch: 15 [12800/26048 (49%)]\tLoss: 0.227576\n",
      "Train Epoch: 15 [25600/26048 (98%)]\tLoss: 0.385942\n",
      "training set: Average loss: 0.2667, Accuracy: 22802/26048 (87.54%)\n",
      "validation set: Average loss: 0.3244, Accuracy: 5540/6513 (85.06%)\n",
      "\n",
      "\n",
      "Train Epoch: 16 [0/26048 (0%)]\tLoss: 0.291889\n",
      "Train Epoch: 16 [12800/26048 (49%)]\tLoss: 0.219329\n",
      "Train Epoch: 16 [25600/26048 (98%)]\tLoss: 0.281495\n",
      "training set: Average loss: 0.2654, Accuracy: 22821/26048 (87.61%)\n",
      "validation set: Average loss: 0.3288, Accuracy: 5547/6513 (85.17%)\n",
      "\n",
      "\n",
      "Train Epoch: 17 [0/26048 (0%)]\tLoss: 0.279556\n",
      "Train Epoch: 17 [12800/26048 (49%)]\tLoss: 0.222928\n",
      "Train Epoch: 17 [25600/26048 (98%)]\tLoss: 0.306402\n",
      "training set: Average loss: 0.2631, Accuracy: 22834/26048 (87.66%)\n",
      "validation set: Average loss: 0.3239, Accuracy: 5561/6513 (85.38%)\n",
      "\n",
      "\n",
      "training set: Average loss: 0.2631, Accuracy: 22834/26048 (87.66%)\n",
      "validation set: Average loss: 0.3239, Accuracy: 5561/6513 (85.38%)\n"
     ]
    }
   ],
   "source": [
    "log_interval = 100\n",
    "epochs = 17\n",
    "max_count = 1\n",
    "print(\"Using Adam optimizer Finer search\") \n",
    "      \n",
    "hidden_set = [2048, 1024, 512, 256, 128, 64, 32, 16] \n",
    "for count in range(max_count):\n",
    "    lr = 0.001\n",
    "    dropout = 0.5\n",
    "    hidden_units = [1024, 256]\n",
    "    l2_reg = 0.001\n",
    "    \n",
    "    print(\"{}, hidden units{}, lr {}, dropout {}, l2_reg {}\".format(count, hidden_units, lr, dropout, l2_reg))\n",
    "    \n",
    "    torch.manual_seed(1234)\n",
    "    model = Net2HiddenLayers(hidden_units[0], hidden_units[1], dropout)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_and_eval(optimizer, model, epochs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: Average loss: 0.3748, Accuracy: 13769/16281 (84.57%)\n"
     ]
    }
   ],
   "source": [
    " evaluate(test_loader, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
